{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyMaymADPiKK6jSgSYmudhhi",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/HazemHassine/Machine-Learning-Components/blob/master/Linear_SVM.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## In this notebook, the algorithms implemented are:\n",
        "1. hinge Loss\n",
        "2. Cost Gradient\n",
        "3. Stochastic Gradient Descent"
      ],
      "metadata": {
        "id": "Wp9qR3gClEg8"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "G4uaavO-S-lW"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "from sklearn.utils import shuffle\n",
        "\n",
        "def compute_cost(weights, X, Y):\n",
        "  N = X.shape[0]\n",
        "  distances = 1 - Y* np.dot(W , X)\n",
        "  distances[distances < 0] = 0 # equal to max(0, distance)\n",
        "  hinge_loss = reguralization_strength * np.sum(distances) / N\n",
        "\n",
        "  cost = 1/2 * np.dot(W,W) + hinge_loss # np.dot(W,W) gets the normal length of W vector\n",
        "\n",
        "  return cost"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def calculate_cost_gradient(W, X_batch, Y_batch):\n",
        "    # if only one example is passed (eg. in case of SGD)\n",
        "    if type(Y_batch) == np.float64:\n",
        "        Y_batch = np.array([Y_batch])\n",
        "        X_batch = np.array([X_batch])  # gives multidimensional array for compatability\n",
        "\n",
        "    distance = 1 - (Y_batch * np.dot(X_batch, W))\n",
        "    dw = np.zeros(len(W))\n",
        "\n",
        "    for ind, d in enumerate(distance):\n",
        "        if max(0, d) == 0:\n",
        "            di = W\n",
        "        else:\n",
        "            di = W - (regularization_strength * Y_batch[ind] * X_batch[ind])\n",
        "            # the regularization strength usually denoted as lambda, or 1/Ci \n",
        "            # this variable dsecribes variance of the margin's width\n",
        "        dw += di\n",
        "\n",
        "    dw = dw/len(Y_batch)  # average\n",
        "    return dw"
      ],
      "metadata": {
        "id": "Nq40fcMfjtma"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def sgd(features, outputs):\n",
        "    max_epochs = 5000\n",
        "    weights = np.zeros(features.shape[1])\n",
        "    nth = 0\n",
        "    prev_cost = float(\"inf\")\n",
        "    cost_threshold = 0.01  # in percent\n",
        "    # stochastic gradient descent\n",
        "    for epoch in range(1, max_epochs):\n",
        "        # shuffle to prevent repeating update cycles\n",
        "        X, Y = shuffle(features, outputs)\n",
        "        for ind, x in enumerate(X):\n",
        "            ascent = calculate_cost_gradient(weights, x, Y[ind])\n",
        "            weights = weights - (learning_rate * ascent)\n",
        "\n",
        "        # convergence check on 2^nth epoch\n",
        "        if epoch == 2 ** nth or epoch == max_epochs - 1:\n",
        "            cost = compute_cost(weights, features, outputs)\n",
        "            print(\"Epoch is: {} and Cost is: {}\".format(epoch, cost))\n",
        "            # stoppage criterion\n",
        "            if abs(prev_cost - cost) < cost_threshold * prev_cost:\n",
        "                return weights\n",
        "            prev_cost = cost\n",
        "            nth += 1\n",
        "    return weights"
      ],
      "metadata": {
        "id": "MOdxDS5CjwVk"
      },
      "execution_count": 3,
      "outputs": []
    }
  ]
}